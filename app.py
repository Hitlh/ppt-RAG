import streamlit as st
import os
import sys
import asyncio
import shutil
from pathlib import Path

# ==========================================
# ğŸ› ï¸ 1. ç¯å¢ƒè‡ªæ£€ä¸å¯¼åŒ… (Environment Check)
# ==========================================
# ç¡®ä¿å½“å‰ç›®å½•åœ¨ sys.path ä¸­ï¼Œé˜²æ­¢ import æŠ¥é”™
current_dir = os.getcwd()
if current_dir not in sys.path:
    sys.path.append(current_dir)

try:
    # å°è¯•å¼•å…¥åç«¯å¼•æ“
    from lightrag.llm.openai import openai_complete_if_cache, openai_embed
    from lightrag.utils import EmbeddingFunc
    from raganything import RAGAnything, RAGAnythingConfig
except ImportError as e:
    st.error(f"âŒ ä¸¥é‡é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ RAG-Anything åº“ï¼\nè¯·ç¡®ä¿ app.py ä½äºé¡¹ç›®æ ¹ç›®å½•ä¸‹ã€‚\nè¯¦ç»†æŠ¥é”™: {e}")
    st.stop()

# ==========================================
# ğŸ¨ 2. é¡µé¢é…ç½® (Page Config)
# ==========================================
st.set_page_config(
    page_title="RAG-Anything Pro (Single Doc Edition)", 
    page_icon="ğŸ“š", 
    layout="wide"
)

# ==========================================
# ğŸ§  3. æ ¸å¿ƒå¼•æ“æœåŠ¡ (Service Layer)
# ==========================================
class RAGService:
    """
    RAG æœåŠ¡å°è£…ç±»ï¼š
    è´Ÿè´£ç®¡ç† RAGAnything å®ä¾‹ï¼Œç¡®ä¿æ¨¡å‹å¸¸é©»å†…å­˜ï¼Œ
    é¿å…æ¯æ¬¡æ“ä½œéƒ½é‡æ–°åŠ è½½æ¨¡å‹ã€‚
    """
    def __init__(self, api_key, base_url, working_dir="./rag_storage6"):
        self.api_key = api_key
        self.base_url = base_url
        self.working_dir = working_dir
        self.rag_instance = None
        
        # è‡ªåŠ¨åˆ›å»ºå·¥ä½œç›®å½•
        if not os.path.exists(working_dir):
            os.makedirs(working_dir)

    def get_engine(self):
        """å•ä¾‹æ¨¡å¼è·å–å¼•æ“å®ä¾‹ (Singleton Pattern)"""
        if self.rag_instance is not None:
            return self.rag_instance

        # === 1. é…ç½®å‚æ•° ===
        config = RAGAnythingConfig(
            working_dir=self.working_dir,
            parser="mineru",  # æŒ‡å®šä½¿ç”¨ MinerU è§£æå™¨
            parse_method="auto",
            enable_image_processing=True,
            enable_table_processing=True,
            enable_equation_processing=True,
        )

        # === 2. å®šä¹‰ LLM è°ƒç”¨å‡½æ•° ===
        def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
            return openai_complete_if_cache(
                "gpt-4o-mini",
                prompt,
                system_prompt=system_prompt,
                history_messages=history_messages,
                api_key=self.api_key,
                base_url=self.base_url,
                **kwargs,
            )

        # === 3. å®šä¹‰ Embedding å‡½æ•° ===
        embedding_func = EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=self.api_key,
                base_url=self.base_url,
            ),
        )

        # === 4. å®šä¹‰è§†è§‰æ¨¡å‹å‡½æ•° (Vision) ===
        def vision_model_func(
            prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
        ):
            if messages:
                return openai_complete_if_cache(
                    "gpt-4o",
                    "",
                    system_prompt=None,
                    history_messages=[],
                    messages=messages,
                    api_key=self.api_key,
                    base_url=self.base_url,
                    **kwargs,
                )
            elif image_data:
                return openai_complete_if_cache(
                    "gpt-4o",
                    "",
                    system_prompt=None,
                    history_messages=[],
                    messages=[
                        {"role": "system", "content": system_prompt} if system_prompt else None,
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {"url": f"data:image/jpeg;base64,{image_data}"},
                                },
                            ],
                        }
                        if image_data
                        else {"role": "user", "content": prompt},
                    ],
                    api_key=self.api_key,
                    base_url=self.base_url,
                    **kwargs,
                )
            else:
                return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

        # === 5. å®ä¾‹åŒ–å¼•æ“ ===
        self.rag_instance = RAGAnything(
            config=config,
            llm_model_func=llm_model_func,
            vision_model_func=vision_model_func,
            embedding_func=embedding_func,
        )
        return self.rag_instance

# å¼‚æ­¥è¿è¡Œè¾…åŠ©å‡½æ•° (è§£å†³ Streamlit åŒæ­¥ç¯å¢ƒè°ƒç”¨å¼‚æ­¥ä»£ç çš„é—®é¢˜)
def run_async(coro):
    try:
        return asyncio.run(coro)
    except RuntimeError:
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(coro)

# ==========================================
# ğŸ–¥ï¸ 4. å‰ç«¯ç•Œé¢é€»è¾‘ (UI Logic)
# ==========================================

# åˆå§‹åŒ– Session State
if "rag_service" not in st.session_state:
    st.session_state.rag_service = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "doc_indexed" not in st.session_state:
    st.session_state.doc_indexed = False
if "current_doc_name" not in st.session_state:
    st.session_state.current_doc_name = ""

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ“š RAG å•æ–‡æ¡£é—®ç­”å™¨")
    st.caption("Single Document Parse + QA")
    st.divider()
    
    # é…ç½®åŒºåŸŸ
    api_key = st.text_input("API Key", type="password")
    base_url = st.text_input("Base URL", value="https://api.yunwu.ai/v1")
    
    if st.button("ğŸ”Œ å¯åŠ¨/é‡ç½®å¼•æ“"):
        st.session_state.rag_service = RAGService(api_key, base_url)
        st.session_state.doc_indexed = False
        st.session_state.current_doc_name = ""
        st.session_state.messages = []
        with st.spinner("æ­£åœ¨åŠ è½½ MinerU æ¨¡å‹ (é¦–æ¬¡è¿è¡Œå¯èƒ½è¾ƒæ…¢)..."):
            st.session_state.rag_service.get_engine()
        st.success("å¼•æ“å·²å°±ç»ªï¼(In-Memory)")
    
    st.divider()
    
    # å•æ–‡æ¡£ä¸Šä¼ åŒºåŸŸ
    uploaded_file = st.file_uploader(
        "ğŸ“„ ä¸Šä¼ ä¸€ä¸ªæ–‡æ¡£è¿›è¡Œè§£æ",
        type=['pdf', 'txt', 'docx', 'pptx'],
        accept_multiple_files=False
    )

    if uploaded_file and st.session_state.rag_service:
        st.info(f"å½“å‰æ–‡ä»¶ï¼š{uploaded_file.name}")

        if st.button("ğŸš€ è§£æå¹¶æ³¨å…¥çŸ¥è¯†åº“"):
            engine = st.session_state.rag_service.get_engine()

            upload_dir = "./temp_uploads"
            if os.path.exists(upload_dir):
                shutil.rmtree(upload_dir)
            os.makedirs(upload_dir)

            file_path = os.path.join(upload_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            try:
                with st.spinner("æ­£åœ¨è§£ææ–‡æ¡£ï¼Œè¯·ç¨å€™..."):
                    print(f"å¼€å§‹è§£ææ–‡æ¡£: {file_path}")
                    run_async(engine.process_document_complete(
                        file_path=file_path,
                        output_dir="./output",
                        parse_method="auto"
                    ))
                st.session_state.doc_indexed = True
                st.session_state.current_doc_name = uploaded_file.name
                st.success(f"âœ… è§£æå®Œæˆï¼š{uploaded_file.name}ï¼Œç°åœ¨å¯ä»¥é—®ç­”äº†ã€‚")
            except Exception as e:
                st.session_state.doc_indexed = False
                st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# --- ä¸»èŠå¤©ç•Œé¢ ---
st.subheader("ğŸ’¬ çŸ¥è¯†åº“é—®ç­”")
if st.session_state.current_doc_name:
    st.caption(f"å½“å‰çŸ¥è¯†åº“æ–‡æ¡£ï¼š{st.session_state.current_doc_name}")

# å›æ˜¾å†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# å¤„ç†è¾“å…¥
if prompt := st.chat_input("åŸºäºæ–‡æ¡£å†…å®¹æé—®..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    
    if st.session_state.rag_service and st.session_state.doc_indexed:
        engine = st.session_state.rag_service.get_engine()
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                # è°ƒç”¨é—®ç­”æ¥å£
                print(f"ç”¨æˆ·æé—®: {prompt}")
                response = run_async(engine.aquery(prompt, mode="hybrid"))
                st.write(response)
        st.session_state.messages.append({"role": "assistant", "content": str(response)})
    elif st.session_state.rag_service and not st.session_state.doc_indexed:
        st.error("è¯·å…ˆä¸Šä¼ å¹¶è§£æä¸€ä¸ªæ–‡æ¡£ï¼Œå†å¼€å§‹é—®ç­”ã€‚")
    else:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§åˆå§‹åŒ–å¼•æ“ï¼")